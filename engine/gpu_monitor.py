"""GPUåŠŸç‡å’Œæ€§èƒ½ç›‘æ§æ¨¡å—

æœ¬æ¨¡å—ç”¨äºåœ¨åŸºå‡†æµ‹è¯•è¿è¡ŒæœŸé—´ç›‘æ§GPUçš„åŠŸç‡æ¶ˆè€—ã€åˆ©ç”¨ç‡ã€å†…å­˜ä½¿ç”¨å’Œæ¸©åº¦ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. å®æ—¶é‡‡é›†GPUç¡¬ä»¶æŒ‡æ ‡ï¼ˆåŠŸç‡ã€æ¸©åº¦ã€åˆ©ç”¨ç‡ç­‰ï¼‰
2. é€šè¿‡æ—¶é—´ç§¯åˆ†æ³•è®¡ç®—èƒ½è€—ï¼ˆæ¢¯å½¢ç§¯åˆ†ï¼‰
3. è®°å½•æ€§èƒ½æŒ‡æ ‡ï¼ˆååé‡ã€å»¶è¿Ÿã€tokenç”Ÿæˆæ•°ç­‰ï¼‰
4. è®¡ç®—èƒ½æ•ˆæŒ‡æ ‡ï¼ˆæ¯ç„¦è€³ç”Ÿæˆçš„tokenæ•°ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    monitor = GPUMonitor(gpu_ids=[0,1,2], sampling_interval=0.5)
    monitor.start()
    # ... è¿è¡Œbenchmark ...
    monitor.stop()
    results = monitor.get_results()
    print_gpu_summary(results)
"""

import subprocess
import time
import json
import threading
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional
from collections import defaultdict
import os
from termcolor import colored


@dataclass
class GPUSnapshot:
    """GPUæŒ‡æ ‡çš„å•æ¬¡å¿«ç…§
    
    å­˜å‚¨æŸä¸€æ—¶åˆ»æ‰€æœ‰GPUç¡¬ä»¶æŒ‡æ ‡å’Œæ€§èƒ½æŒ‡æ ‡çš„å¿«ç…§æ•°æ®ã€‚
    æ¯ä¸ªé‡‡æ ·é—´éš”ï¼ˆå¦‚0.5ç§’ï¼‰ä¼šç”Ÿæˆä¸€æ¬¡å¿«ç…§ã€‚
    """
    # æ—¶é—´æˆ³å’Œæ ‡è¯†
    timestamp: float            # é‡‡æ ·æ—¶é—´æˆ³ï¼ˆUnixæ—¶é—´ï¼‰
    gpu_id: int                 # GPUç¼–å·ï¼ˆ0-7ï¼‰
    
    # åŠŸç‡æŒ‡æ ‡ï¼ˆé€šè¿‡nvidia-smiæŸ¥è¯¢ï¼‰
    power_draw: float           # å½“å‰åŠŸç‡æ¶ˆè€—ï¼ˆç“¦ç‰¹ï¼‰
    power_limit: float          # åŠŸç‡ä¸Šé™ï¼ˆç“¦ç‰¹ï¼‰
    
    # åˆ©ç”¨ç‡æŒ‡æ ‡
    utilization_gpu: float      # GPUè®¡ç®—åˆ©ç”¨ç‡ï¼ˆç™¾åˆ†æ¯” 0-100ï¼‰
    utilization_memory: float   # æ˜¾å­˜å¸¦å®½åˆ©ç”¨ç‡ï¼ˆç™¾åˆ†æ¯” 0-100ï¼‰
    
    # æ˜¾å­˜ä½¿ç”¨
    memory_used: int            # å·²ä½¿ç”¨æ˜¾å­˜ï¼ˆMBï¼‰
    memory_total: int           # æ€»æ˜¾å­˜ï¼ˆMBï¼‰
    
    # æ¸©åº¦å’Œé¢‘ç‡
    temperature: float          # GPUæ¸©åº¦ï¼ˆæ‘„æ°åº¦ï¼‰
    clock_graphics: int         # GPUæ ¸å¿ƒé¢‘ç‡ï¼ˆMHzï¼‰
    clock_memory: int           # æ˜¾å­˜é¢‘ç‡ï¼ˆMHzï¼‰
    
    # æ€§èƒ½æŒ‡æ ‡ï¼ˆç”±benchmarkå›è°ƒå‡½æ•°è®¾ç½®ï¼Œå¯é€‰ï¼‰
    total_tokens_generated: int = 0  # æˆªè‡³å½“å‰å·²ç”Ÿæˆçš„æ€»tokenæ•°
    total_tokens_accepted: int = 0   # æˆªè‡³å½“å‰å·²æ¥å—çš„tokenæ•°ï¼ˆæ¨æµ‹è§£ç ï¼‰
    requests_completed: int = 0      # æˆªè‡³å½“å‰å·²å®Œæˆçš„è¯·æ±‚æ•°
    throughput: float = 0.0          # å½“å‰ååé‡ï¼ˆtokens/ç§’ï¼‰
    avg_ttft: float = 0.0            # å½“å‰å¹³å‡é¦–tokenæ—¶é—´ï¼ˆç§’ï¼‰
    avg_latency: float = 0.0         # å½“å‰å¹³å‡å»¶è¿Ÿï¼ˆç§’ï¼‰


@dataclass
class GPUMonitorResults:
    """GPUç›‘æ§ç»“æœæ±‡æ€»
    
    åŒ…å«æ•´ä¸ªbenchmarkè¿‡ç¨‹ä¸­çš„æ‰€æœ‰GPUå¿«ç…§æ•°æ®ï¼Œ
    å¹¶æä¾›è®¡ç®—èƒ½è€—ã€å¹³å‡åŠŸç‡ç­‰è¡ç”ŸæŒ‡æ ‡çš„æ–¹æ³•ã€‚
    """
    gpu_ids: List[int] = field(default_factory=list)      # ç›‘æ§çš„GPUåˆ—è¡¨
    snapshots: List[GPUSnapshot] = field(default_factory=list)  # æ‰€æœ‰é‡‡æ ·å¿«ç…§
    start_time: float = 0.0  # ç›‘æ§å¼€å§‹æ—¶é—´ï¼ˆUnixæ—¶é—´æˆ³ï¼‰
    end_time: float = 0.0    # ç›‘æ§ç»“æŸæ—¶é—´ï¼ˆUnixæ—¶é—´æˆ³ï¼‰
    
    # æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡ï¼ˆåœ¨benchmarkç»“æŸæ—¶è®¾ç½®ï¼‰
    total_tokens_generated: int = 0    # æ€»å…±ç”Ÿæˆçš„tokenæ•°
    total_tokens_accepted: int = 0     # æ€»å…±æ¥å—çš„tokenæ•°ï¼ˆæ¨æµ‹è§£ç ï¼‰
    total_requests: int = 0            # æ€»å…±å®Œæˆçš„è¯·æ±‚æ•°
    
    @property
    def duration(self) -> float:
        """ç›‘æ§æ€»æ—¶é•¿ï¼ˆç§’ï¼‰"""
        return self.end_time - self.start_time
    
    @property
    def total_energy_consumed(self) -> Dict[int, float]:
        """è®¡ç®—æ¯ä¸ªGPUçš„æ€»èƒ½è€—ï¼ˆç„¦è€³ï¼‰
        
        ä½¿ç”¨æ¢¯å½¢ç§¯åˆ†æ³•è®¡ç®—èƒ½è€—ï¼š
        E = âˆ« P(t) dt â‰ˆ Î£ [(P[i] + P[i+1]) / 2 * Î”t]
        
        ç®—æ³•æµç¨‹ï¼š
        1. æŒ‰GPUåˆ†ç»„æ‰€æœ‰å¿«ç…§
        2. æŒ‰æ—¶é—´æ’åº
        3. å¯¹ç›¸é‚»ä¸¤ä¸ªé‡‡æ ·ç‚¹ï¼Œè®¡ç®—ï¼š
           - æ—¶é—´é—´éš” Î”t = t[i+1] - t[i]
           - å¹³å‡åŠŸç‡ P_avg = (P[i] + P[i+1]) / 2
           - èƒ½é‡å¢é‡ Î”E = P_avg * Î”t
        4. ç´¯åŠ æ‰€æœ‰æ—¶é—´æ®µçš„èƒ½é‡
        
        è¿”å›ï¼š
            Dict[gpu_id, energy_joules]: æ¯ä¸ªGPUçš„æ€»èƒ½è€—ï¼ˆç„¦è€³ï¼‰
        
        ç¤ºä¾‹ï¼š
            {0: 150.5, 1: 148.2, ...}  # GPU 0æ¶ˆè€—150.5ç„¦è€³
        """
        energy = defaultdict(float)
        
        # æŒ‰GPUåˆ†ç»„å¿«ç…§
        gpu_snapshots = defaultdict(list)
        for snapshot in self.snapshots:
            gpu_snapshots[snapshot.gpu_id].append(snapshot)
        
        # å¯¹æ¯ä¸ªGPUè®¡ç®—èƒ½è€—
        for gpu_id, snapshots in gpu_snapshots.items():
            if len(snapshots) < 2:
                continue  # å°‘äº2ä¸ªé‡‡æ ·ç‚¹æ— æ³•ç§¯åˆ†
            
            # æŒ‰æ—¶é—´æ’åº
            snapshots.sort(key=lambda x: x.timestamp)
            
            # æ¢¯å½¢ç§¯åˆ†ï¼šç´¯åŠ æ¯ä¸ªæ—¶é—´æ®µçš„èƒ½é‡
            for i in range(len(snapshots) - 1):
                dt = snapshots[i + 1].timestamp - snapshots[i].timestamp  # æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
                avg_power = (snapshots[i].power_draw + snapshots[i + 1].power_draw) / 2  # å¹³å‡åŠŸç‡ï¼ˆç“¦ç‰¹ï¼‰
                energy[gpu_id] += avg_power * dt  # èƒ½é‡ = åŠŸç‡ Ã— æ—¶é—´ï¼ˆç„¦è€³ï¼‰
        
        return dict(energy)
    
    @property
    def average_power(self) -> Dict[int, float]:
        """Average power consumption per GPU in Watts."""
        power_sum = defaultdict(float)
        power_count = defaultdict(int)
        
        for snapshot in self.snapshots:
            power_sum[snapshot.gpu_id] += snapshot.power_draw
            power_count[snapshot.gpu_id] += 1
        
        return {
            gpu_id: power_sum[gpu_id] / power_count[gpu_id] 
            if power_count[gpu_id] > 0 else 0.0
            for gpu_id in power_sum.keys()
        }
    
    @property
    def peak_power(self) -> Dict[int, float]:
        """Peak power consumption per GPU in Watts."""
        peak = defaultdict(float)
        for snapshot in self.snapshots:
            peak[snapshot.gpu_id] = max(peak[snapshot.gpu_id], snapshot.power_draw)
        return dict(peak)
    
    @property
    def average_utilization(self) -> Dict[int, float]:
        """Average GPU utilization per GPU in percentage."""
        util_sum = defaultdict(float)
        util_count = defaultdict(int)
        
        for snapshot in self.snapshots:
            util_sum[snapshot.gpu_id] += snapshot.utilization_gpu
            util_count[snapshot.gpu_id] += 1
        
        return {
            gpu_id: util_sum[gpu_id] / util_count[gpu_id] 
            if util_count[gpu_id] > 0 else 0.0
            for gpu_id in util_sum.keys()
        }
    
    @property
    def average_memory_usage(self) -> Dict[int, float]:
        """Average memory usage per GPU in percentage."""
        mem_sum = defaultdict(float)
        mem_count = defaultdict(int)
        
        for snapshot in self.snapshots:
            mem_pct = (snapshot.memory_used / snapshot.memory_total * 100) if snapshot.memory_total > 0 else 0
            mem_sum[snapshot.gpu_id] += mem_pct
            mem_count[snapshot.gpu_id] += 1
        
        return {
            gpu_id: mem_sum[gpu_id] / mem_count[gpu_id] 
            if mem_count[gpu_id] > 0 else 0.0
            for gpu_id in mem_sum.keys()
        }
    
    @property
    def peak_temperature(self) -> Dict[int, float]:
        """Peak temperature per GPU in Celsius."""
        temp = defaultdict(float)
        for snapshot in self.snapshots:
            temp[snapshot.gpu_id] = max(temp[snapshot.gpu_id], snapshot.temperature)
        return dict(temp)
    
    @property
    def total_energy_all_gpus(self) -> float:
        """Total energy consumed across all GPUs in Joules."""
        return sum(self.total_energy_consumed.values())
    
    @property
    def tokens_per_joule(self) -> float:
        """æ¯ç„¦è€³ç”Ÿæˆçš„tokenæ•°ï¼ˆèƒ½æ•ˆæŒ‡æ ‡ï¼‰
        
        è®¡ç®—å…¬å¼ï¼štokens_per_joule = æ€»tokenæ•° / æ€»èƒ½è€—(ç„¦è€³)
        
        è¿™æ˜¯è¡¡é‡æ¨ç†èƒ½æ•ˆçš„æ ¸å¿ƒæŒ‡æ ‡ï¼Œæ•°å€¼è¶Šé«˜è¡¨ç¤ºèƒ½æ•ˆè¶Šå¥½ã€‚
        
        è¿”å›ï¼š
            float: æ¯ç„¦è€³ç”Ÿæˆçš„tokenæ•°ï¼ˆtokens/Jï¼‰
        
        ç¤ºä¾‹ï¼š
            2.5 tokens/J è¡¨ç¤ºæ¶ˆè€—1ç„¦è€³èƒ½é‡å¯ä»¥ç”Ÿæˆ2.5ä¸ªtoken
        """
        if self.total_energy_all_gpus <= 0:
            return 0.0
        return self.total_tokens_generated / self.total_energy_all_gpus
    
    @property
    def tokens_accepted_per_joule(self) -> float:
        """æ¯ç„¦è€³æ¥å—çš„tokenæ•°ï¼ˆæ¨æµ‹è§£ç ä¸“ç”¨èƒ½æ•ˆæŒ‡æ ‡ï¼‰
        
        ä»…ç”¨äºæ¨æµ‹è§£ç æ¨¡å¼ï¼Œè®¡ç®—è¢«targetæ¨¡å‹æ¥å—çš„tokenä¸èƒ½è€—çš„æ¯”ç‡ã€‚
        æ¥å—çš„tokenæ•° < ç”Ÿæˆçš„tokenæ•°ï¼ˆå› ä¸ºæœ‰äº›draft tokenä¼šè¢«æ‹’ç»ï¼‰ã€‚
        
        è®¡ç®—å…¬å¼ï¼štokens_accepted_per_joule = æ¥å—çš„tokenæ•° / æ€»èƒ½è€—(ç„¦è€³)
        
        è¿”å›ï¼š
            float: æ¯ç„¦è€³æ¥å—çš„tokenæ•°ï¼ˆtokens/Jï¼‰
        """
        if self.total_energy_all_gpus <= 0:
            return 0.0
        if self.total_tokens_accepted > 0:
            return self.total_tokens_accepted / self.total_energy_all_gpus
        # å¦‚æœæ²¡æœ‰æ¥å—æ•°æ®ï¼ˆéæ¨æµ‹è§£ç æ¨¡å¼ï¼‰ï¼Œå›é€€åˆ°ç”Ÿæˆæ•°
        return self.total_tokens_generated / self.total_energy_all_gpus
    
    @property
    def tokens_per_kwh(self) -> float:
        """æ¯åƒç“¦æ—¶ç”Ÿæˆçš„tokenæ•°ï¼ˆå·¥ä¸šåŒ–èƒ½æ•ˆæŒ‡æ ‡ï¼‰
        
        å°†èƒ½è€—è½¬æ¢ä¸ºæ›´ç›´è§‚çš„åƒç“¦æ—¶(kWh)å•ä½ï¼Œä¾¿äºä¸ç”µè´¹æŒ‚é’©ã€‚
        
        è½¬æ¢å…³ç³»ï¼š
        1 kWh = 3,600,000 J (1åƒç“¦æ—¶ = 1000ç“¦ Ã— 3600ç§’)
        
        è®¡ç®—å…¬å¼ï¼š
        1. èƒ½è€—(kWh) = æ€»èƒ½è€—(ç„¦è€³) / 3,600,000
        2. tokens_per_kwh = æ€»tokenæ•° / èƒ½è€—(kWh)
        
        è¿”å›ï¼š
            float: æ¯åƒç“¦æ—¶ç”Ÿæˆçš„tokenæ•°ï¼ˆtokens/kWhï¼‰
        
        å®é™…åº”ç”¨ç¤ºä¾‹ï¼š
            tokens_per_kwh = 1,000,000
            ç”µè´¹å•ä»· = 0.6å…ƒ/kWh
            â†’ ç”Ÿæˆ100ä¸‡tokenéœ€è¦1åº¦ç”µï¼Œæˆæœ¬0.6å…ƒ
        """
        energy_kwh = self.total_energy_all_gpus / 3600000  # ç„¦è€³è½¬åƒç“¦æ—¶
        if energy_kwh <= 0:
            return 0.0
        return self.total_tokens_generated / energy_kwh
    
    @property
    def tokens_accepted_per_kwh(self) -> float:
        """æ¯åƒç“¦æ—¶æ¥å—çš„tokenæ•°ï¼ˆæ¨æµ‹è§£ç ä¸“ç”¨ï¼Œå·¥ä¸šåŒ–æŒ‡æ ‡ï¼‰
        
        ç»“åˆæ¨æµ‹è§£ç å’Œå·¥ä¸šåŒ–å•ä½ï¼Œç”¨äºè¯„ä¼°æ¨æµ‹è§£ç çš„å®é™…èƒ½æ•ˆæ”¶ç›Šã€‚
        
        è®¡ç®—å…¬å¼ï¼š
        1. èƒ½è€—(kWh) = æ€»èƒ½è€—(ç„¦è€³) / 3,600,000
        2. tokens_accepted_per_kwh = æ¥å—çš„tokenæ•° / èƒ½è€—(kWh)
        
        è¿”å›ï¼š
            float: æ¯åƒç“¦æ—¶æ¥å—çš„tokenæ•°ï¼ˆtokens/kWhï¼‰
        
        å¯¹æ¯”æ„ä¹‰ï¼š
        - tokens_per_kwh: è¡¡é‡"ç”Ÿæˆ"æ•ˆç‡ï¼ˆåŒ…æ‹¬è¢«æ‹’ç»çš„draftï¼‰
        - tokens_accepted_per_kwh: è¡¡é‡"æœ‰æ•ˆäº§å‡º"æ•ˆç‡ï¼ˆä»…è¢«æ¥å—çš„ï¼‰
        """
        energy_kwh = self.total_energy_all_gpus / 3600000  # ç„¦è€³è½¬åƒç“¦æ—¶
        if energy_kwh <= 0:
            return 0.0
        if self.total_tokens_accepted > 0:
            return self.total_tokens_accepted / energy_kwh
        return self.total_tokens_generated / energy_kwh
    
    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "gpu_ids": self.gpu_ids,
            "duration": self.duration,
            "start_time": self.start_time,
            "end_time": self.end_time,
            "total_energy_consumed": {str(k): v for k, v in self.total_energy_consumed.items()},
            "total_energy_all_gpus": self.total_energy_all_gpus,
            "average_power": {str(k): v for k, v in self.average_power.items()},
            "peak_power": {str(k): v for k, v in self.peak_power.items()},
            "average_utilization": {str(k): v for k, v in self.average_utilization.items()},
            "average_memory_usage": {str(k): v for k, v in self.average_memory_usage.items()},
            "peak_temperature": {str(k): v for k, v in self.peak_temperature.items()},
            "total_tokens_generated": self.total_tokens_generated,
            "total_tokens_accepted": self.total_tokens_accepted,
            "total_requests": self.total_requests,
            "tokens_per_joule": self.tokens_per_joule,
            "tokens_accepted_per_joule": self.tokens_accepted_per_joule,
            "tokens_per_kwh": self.tokens_per_kwh,
            "tokens_accepted_per_kwh": self.tokens_accepted_per_kwh,
            "snapshots": [asdict(s) for s in self.snapshots]
        }


class GPUMonitor:
    """Monitors GPU power and performance metrics."""
    
    def __init__(self, gpu_ids: Optional[List[int]] = None, sampling_interval: float = 1.0, 
                 performance_callback: Optional[callable] = None):
        """
        Initialize GPU monitor.
        
        Args:
            gpu_ids: List of GPU IDs to monitor. If None, monitors all available GPUs.
            sampling_interval: Sampling interval in seconds (default: 1.0).
            performance_callback: Optional callback function that returns performance metrics dict:
                {
                    'total_tokens_generated': int,
                    'total_tokens_accepted': int,
                    'requests_completed': int,
                    'throughput': float,
                    'avg_ttft': float,
                    'avg_latency': float
                }
        """
        self.gpu_ids = gpu_ids if gpu_ids is not None else self._detect_gpu_ids()
        self.sampling_interval = sampling_interval
        self.performance_callback = performance_callback
        self.results = GPUMonitorResults(gpu_ids=self.gpu_ids)
        self._monitoring = False
        self._monitor_thread = None
        
    def _detect_gpu_ids(self) -> List[int]:
        """Detect available GPU IDs."""
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=index", "--format=csv,noheader,nounits"],
                capture_output=True,
                text=True,
                check=True
            )
            gpu_ids = [int(line.strip()) for line in result.stdout.strip().split('\n') if line.strip()]
            return gpu_ids
        except (subprocess.CalledProcessError, FileNotFoundError, ValueError) as e:
            print(colored(f"âš ï¸  Warning: Could not detect GPUs: {e}", "yellow"))
            return []
    
    def _query_gpu_metrics(self, gpu_id: int) -> Optional[GPUSnapshot]:
        """Query metrics for a single GPU."""
        try:
            query = (
                "index,power.draw,power.limit,utilization.gpu,utilization.memory,"
                "memory.used,memory.total,temperature.gpu,clocks.current.graphics,"
                "clocks.current.memory"
            )
            
            result = subprocess.run(
                [
                    "nvidia-smi",
                    f"--id={gpu_id}",
                    f"--query-gpu={query}",
                    "--format=csv,noheader,nounits"
                ],
                capture_output=True,
                text=True,
                check=True,
                timeout=5
            )
            
            parts = result.stdout.strip().split(', ')
            if len(parts) < 10:
                return None
            
            timestamp = time.time()
            return GPUSnapshot(
                timestamp=timestamp,
                gpu_id=int(parts[0]),
                power_draw=float(parts[1]) if parts[1] != '[Not Supported]' else 0.0,
                power_limit=float(parts[2]) if parts[2] != '[Not Supported]' else 0.0,
                utilization_gpu=float(parts[3]) if parts[3] != '[Not Supported]' else 0.0,
                utilization_memory=float(parts[4]) if parts[4] != '[Not Supported]' else 0.0,
                memory_used=int(parts[5]) if parts[5] != '[Not Supported]' else 0,
                memory_total=int(parts[6]) if parts[6] != '[Not Supported]' else 0,
                temperature=float(parts[7]) if parts[7] != '[Not Supported]' else 0.0,
                clock_graphics=int(parts[8]) if parts[8] != '[Not Supported]' else 0,
                clock_memory=int(parts[9]) if parts[9] != '[Not Supported]' else 0,
            )
        except (subprocess.CalledProcessError, ValueError, subprocess.TimeoutExpired) as e:
            print(colored(f"âš ï¸  Warning: Could not query GPU {gpu_id}: {e}", "yellow"))
            return None
    
    def _monitor_loop(self):
        """Main monitoring loop running in background thread."""
        while self._monitoring:
            snapshot_time = time.time()
            
            # Get performance metrics if callback is available
            perf_metrics = {}
            if self.performance_callback:
                try:
                    perf_metrics = self.performance_callback() or {}
                except Exception as e:
                    print(colored(f"âš ï¸  Warning: Performance callback error: {e}", "yellow"))
            
            for gpu_id in self.gpu_ids:
                snapshot = self._query_gpu_metrics(gpu_id)
                if snapshot:
                    # Add performance metrics to snapshot
                    snapshot.total_tokens_generated = perf_metrics.get('total_tokens_generated', 0)
                    snapshot.total_tokens_accepted = perf_metrics.get('total_tokens_accepted', 0)
                    snapshot.requests_completed = perf_metrics.get('requests_completed', 0)
                    snapshot.throughput = perf_metrics.get('throughput', 0.0)
                    snapshot.avg_ttft = perf_metrics.get('avg_ttft', 0.0)
                    snapshot.avg_latency = perf_metrics.get('avg_latency', 0.0)
                    
                    self.results.snapshots.append(snapshot)
            
            # Sleep until next sampling interval
            elapsed = time.time() - snapshot_time
            sleep_time = max(0, self.sampling_interval - elapsed)
            time.sleep(sleep_time)
    
    def start(self):
        """Start GPU monitoring."""
        if self._monitoring:
            print(colored("âš ï¸  Warning: Monitor already running", "yellow"))
            return
        
        self.results = GPUMonitorResults(gpu_ids=self.gpu_ids)
        self.results.start_time = time.time()
        self._monitoring = True
        
        self._monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self._monitor_thread.start()
        
        print(colored(f"âœ… GPU Monitor started (GPUs: {self.gpu_ids}, interval: {self.sampling_interval}s)", "green"))
    
    def stop(self):
        """Stop GPU monitoring."""
        if not self._monitoring:
            return
        
        self._monitoring = False
        if self._monitor_thread:
            self._monitor_thread.join(timeout=5)
        
        self.results.end_time = time.time()
        print(colored("âœ… GPU Monitor stopped", "green"))
    
    def get_results(self) -> GPUMonitorResults:
        """Get monitoring results."""
        return self.results
    
    def save_results(self, filepath: str, results: Optional[GPUMonitorResults] = None):
        """Save results to JSON file."""
        results_to_save = results if results is not None else self.results
        with open(filepath, 'w') as f:
            json.dump(results_to_save.to_dict(), f, indent=2)
        print(colored(f"âœ… GPU monitoring results saved to {filepath}", "green"))


def print_gpu_summary(results: GPUMonitorResults):
    """Print formatted summary of GPU monitoring results."""
    print(colored("\n" + "=" * 70, "cyan", attrs=["bold"]))
    print(colored("ğŸ“Š GPU Power & Performance Summary", "cyan", attrs=["bold"]))
    print(colored("=" * 70, "cyan", attrs=["bold"]))
    
    print(colored("\nâš¡ Power Consumption:", "yellow", attrs=["bold"]))
    total_energy = 0.0
    total_avg_power = 0.0
    
    for gpu_id in results.gpu_ids:
        energy = results.total_energy_consumed.get(gpu_id, 0.0)
        avg_power = results.average_power.get(gpu_id, 0.0)
        peak_power = results.peak_power.get(gpu_id, 0.0)
        
        energy_wh = energy / 3600  # Convert Joules to Wh
        
        print(f"  GPU {gpu_id}:")
        print(f"    Average Power:     {avg_power:.2f} W")
        print(f"    Peak Power:        {peak_power:.2f} W")
        print(f"    Total Energy:      {energy_wh:.2f} Wh ({energy:.2f} J)")
        
        total_energy += energy
        total_avg_power += avg_power
    
    print(f"\n  Total (All GPUs):")
    print(f"    Average Power:     {total_avg_power:.2f} W")
    energy_wh_total = total_energy / 3600
    energy_kwh_total = energy_wh_total / 1000
    print(f"    Total Energy:      {energy_wh_total:.2f} Wh ({energy_kwh_total:.4f} kWh)")
    
    print(colored("\nğŸ“ˆ Utilization:", "yellow", attrs=["bold"]))
    for gpu_id in results.gpu_ids:
        util = results.average_utilization.get(gpu_id, 0.0)
        mem_usage = results.average_memory_usage.get(gpu_id, 0.0)
        print(f"  GPU {gpu_id}:")
        print(f"    GPU Utilization:  {util:.1f}%")
        print(f"    Memory Usage:      {mem_usage:.1f}%")
    
    print(colored("\nğŸŒ¡ï¸  Temperature:", "yellow", attrs=["bold"]))
    for gpu_id in results.gpu_ids:
        temp = results.peak_temperature.get(gpu_id, 0.0)
        print(f"  GPU {gpu_id}: Peak Temperature: {temp:.1f}Â°C")
    
    if results.total_tokens_generated > 0:
        print(colored("\nğŸ¯ Performance Metrics:", "yellow", attrs=["bold"]))
        print(f"  Total Tokens Generated: {results.total_tokens_generated:,}")
        if results.total_tokens_accepted > 0:
            print(f"  Total Tokens Accepted:   {results.total_tokens_accepted:,}")
        print(f"  Total Requests:         {results.total_requests}")
        
        print(colored("\nâš¡ Energy Efficiency:", "yellow", attrs=["bold"]))
        print(f"  Tokens per Joule:       {results.tokens_per_joule:.2f} tokens/J")
        print(f"  Tokens per kWh:         {results.tokens_per_kwh:,.0f} tokens/kWh")
        if results.total_tokens_accepted > 0:
            print(f"  Accepted Tokens per Joule: {results.tokens_accepted_per_joule:.2f} tokens/J")
            print(f"  Accepted Tokens per kWh:   {results.tokens_accepted_per_kwh:,.0f} tokens/kWh")
    
    print(colored(f"\nâ±ï¸  Monitoring Duration: {results.duration:.2f} s", "yellow", attrs=["bold"]))
    print(colored("=" * 70, "cyan", attrs=["bold"]))

